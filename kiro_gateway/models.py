# -*- coding: utf-8 -*-

# KiroGate
# Based on kiro-openai-gateway by Jwadow (https://github.com/Jwadow/kiro-openai-gateway)
# Original Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
OpenAI 兼容 API 的 Pydantic 模型。

定义请求和响应的数据模式，提供验证和序列化功能。
"""

import time
from typing import Any, Dict, List, Optional, Union
from typing_extensions import Annotated
from pydantic import BaseModel, Field, field_validator


# ==================================================================================================
# /v1/models 端点模型
# ==================================================================================================

class OpenAIModel(BaseModel):
    """
    OpenAI 格式的 AI 模型描述。

    用于 /v1/models 端点的响应。
    """
    id: str
    object: str = "model"
    created: int = Field(default_factory=lambda: int(time.time()))
    owned_by: str = "anthropic"
    description: Optional[str] = None


class ModelList(BaseModel):
    """
    OpenAI 格式的模型列表。

    GET /v1/models 端点的响应。
    """
    object: str = "list"
    data: List[OpenAIModel]


# ==================================================================================================
# /v1/chat/completions 端点模型
# ==================================================================================================

class ChatMessage(BaseModel):
    """
    OpenAI 格式的聊天消息。

    支持多种角色（user、assistant、system、tool）和多种内容格式（字符串、列表、对象）。

    Attributes:
        role: 发送者角色（user、assistant、system、tool）
        content: 消息内容（可以是字符串、列表或 None）
        name: 可选的发送者名称
        tool_calls: 工具调用列表（用于 assistant）
        tool_call_id: 工具调用 ID（用于 tool）
    """
    role: str
    content: Optional[Union[str, List[Any], Any]] = None
    name: Optional[str] = None
    tool_calls: Optional[List[Any]] = None
    tool_call_id: Optional[str] = None
    
    model_config = {"extra": "allow"}


class ToolFunction(BaseModel):
    """
    工具函数描述。

    Attributes:
        name: 函数名称
        description: 函数描述
        parameters: 函数参数的 JSON Schema
    """
    name: str
    description: Optional[str] = None
    parameters: Optional[Dict[str, Any]] = None


class Tool(BaseModel):
    """
    OpenAI 格式的工具。

    Attributes:
        type: 工具类型（通常为 "function"）
        function: 函数描述
    """
    type: str = "function"
    function: ToolFunction


class ChatCompletionRequest(BaseModel):
    """
    OpenAI Chat Completions API 格式的请求。

    支持所有标准 OpenAI API 字段，包括：
    - 基本参数（model、messages、stream）
    - 生成参数（temperature、top_p、max_tokens）
    - 工具调用（function calling）
    - 兼容性参数（接受但忽略）

    Attributes:
        model: 生成模型 ID
        messages: 聊天消息列表
        stream: 是否使用流式响应（默认 False）
        temperature: 生成温度（0-2）
        top_p: Top-p 采样
        n: 响应变体数量
        max_tokens: 响应最大 token 数
        max_completion_tokens: max_tokens 的替代字段
        stop: 停止序列
        presence_penalty: 主题重复惩罚
        frequency_penalty: 词汇重复惩罚
        tools: 可用工具列表
        tool_choice: 工具选择策略
    """
    model: str
    messages: Annotated[List[ChatMessage], Field(min_length=1)]
    stream: bool = False

    # 生成参数
    temperature: Optional[float] = None
    top_p: Optional[float] = None
    n: Optional[int] = 1
    max_tokens: Optional[int] = None
    max_completion_tokens: Optional[int] = None
    stop: Optional[Union[str, List[str]]] = None
    presence_penalty: Optional[float] = None
    frequency_penalty: Optional[float] = None

    # 工具调用 - 支持 OpenAI 和 Anthropic 格式
    tools: Optional[List[Union[Tool, Dict[str, Any]]]] = None
    tool_choice: Optional[Union[str, Dict]] = None

    # 兼容性字段（忽略）
    stream_options: Optional[Dict[str, Any]] = None
    logit_bias: Optional[Dict[str, float]] = None
    logprobs: Optional[bool] = None
    top_logprobs: Optional[int] = None
    user: Optional[str] = None
    seed: Optional[int] = None
    parallel_tool_calls: Optional[bool] = None

    model_config = {"extra": "allow"}

    @field_validator('tools', mode='before')
    @classmethod
    def convert_anthropic_tools(cls, v):
        """
        自动转换 Anthropic 格式的 tools 为 OpenAI 格式。

        如果检测到 Anthropic 格式（有 input_schema 字段），
        自动转换为 OpenAI 格式（function.parameters）。
        """
        if v is None:
            return v

        converted_tools = []
        for tool in v:
            # 如果已经是 Tool 对象，直接使用
            if isinstance(tool, Tool):
                converted_tools.append(tool)
                continue

            # 如果是字典
            if isinstance(tool, dict):
                # 检测 Anthropic 格式: 有 name, description, input_schema
                if 'input_schema' in tool and 'name' in tool:
                    # 转换为 OpenAI 格式
                    converted_tool = Tool(
                        type='function',
                        function=ToolFunction(
                            name=tool['name'],
                            description=tool.get('description'),
                            parameters=tool['input_schema']
                        )
                    )
                    converted_tools.append(converted_tool)
                # 检测 OpenAI 格式: 有 function 字段
                elif 'function' in tool:
                    converted_tools.append(tool)
                else:
                    # 未知格式，保持原样
                    converted_tools.append(tool)
            else:
                converted_tools.append(tool)

        return converted_tools


# ==================================================================================================
# 响应模型
# ==================================================================================================

class ChatCompletionChoice(BaseModel):
    """
    Chat Completion 的单个响应选项。

    Attributes:
        index: 选项索引
        message: 响应消息
        finish_reason: 完成原因（stop、tool_calls、length）
    """
    index: int = 0
    message: Dict[str, Any]
    finish_reason: Optional[str] = None


class ChatCompletionUsage(BaseModel):
    """
    Token 使用信息。

    Attributes:
        prompt_tokens: 请求 token 数
        completion_tokens: 响应 token 数
        total_tokens: 总 token 数
        credits_used: 使用的积分（Kiro 特有）
    """
    prompt_tokens: int = 0
    completion_tokens: int = 0
    total_tokens: int = 0
    credits_used: Optional[float] = None


class ChatCompletionResponse(BaseModel):
    """
    Chat Completion 完整响应（非流式）。

    Attributes:
        id: 响应唯一 ID
        object: 对象类型（"chat.completion"）
        created: 创建时间戳
        model: 使用的模型
        choices: 响应选项列表
        usage: Token 使用信息
    """
    id: str
    object: str = "chat.completion"
    created: int = Field(default_factory=lambda: int(time.time()))
    model: str
    choices: List[ChatCompletionChoice]
    usage: ChatCompletionUsage


class ChatCompletionChunkDelta(BaseModel):
    """
    流式 chunk 的增量变化。

    Attributes:
        role: 角色（仅在第一个 chunk 中）
        content: 新内容
        tool_calls: 新的工具调用
    """
    role: Optional[str] = None
    content: Optional[str] = None
    tool_calls: Optional[List[Dict[str, Any]]] = None


class ChatCompletionChunkChoice(BaseModel):
    """
    流式 chunk 中的单个选项。

    Attributes:
        index: 选项索引
        delta: 增量变化
        finish_reason: 完成原因（仅在最后一个 chunk 中）
    """
    index: int = 0
    delta: ChatCompletionChunkDelta
    finish_reason: Optional[str] = None


class ChatCompletionChunk(BaseModel):
    """
    OpenAI 格式的流式 chunk。

    Attributes:
        id: 响应唯一 ID
        object: 对象类型（"chat.completion.chunk"）
        created: 创建时间戳
        model: 使用的模型
        choices: 选项列表
        usage: 使用信息（仅在最后一个 chunk 中）
    """
    id: str
    object: str = "chat.completion.chunk"
    created: int = Field(default_factory=lambda: int(time.time()))
    model: str
    choices: List[ChatCompletionChunkChoice]
    usage: Optional[ChatCompletionUsage] = None


# ==================================================================================================
# Anthropic Messages API 模型 (/v1/messages)
# ==================================================================================================

class AnthropicContentBlock(BaseModel):
    """
    Anthropic Messages API 的内容块。

    支持多种内容类型：text、image、tool_use、tool_result、thinking。

    Attributes:
        type: 内容类型
        text: 文本内容（type="text" 时）
        source: 图片来源（type="image" 时）
        id: tool_use ID（type="tool_use" 时）
        name: 工具名称（type="tool_use" 时）
        input: 工具输入数据（type="tool_use" 时）
        tool_use_id: 关联的 tool_use ID（type="tool_result" 时）
        content: 工具结果（type="tool_result" 时）
        is_error: 错误标志（type="tool_result" 时）
        thinking: thinking 内容（type="thinking" 时）
    """
    type: str  # "text", "image", "tool_use", "tool_result", "thinking"
    text: Optional[str] = None
    # image fields
    source: Optional[Dict[str, Any]] = None  # {"type": "base64"/"url", "media_type": "...", "data"/"url": "..."}
    # tool_use fields
    id: Optional[str] = None
    name: Optional[str] = None
    input: Optional[Dict[str, Any]] = None
    # tool_result fields
    tool_use_id: Optional[str] = None
    content: Optional[Union[str, List[Any]]] = None
    is_error: Optional[bool] = None
    # thinking fields
    thinking: Optional[str] = None

    model_config = {"extra": "allow"}


class AnthropicMessage(BaseModel):
    """
    Anthropic 格式的消息。

    Attributes:
        role: 角色（user 或 assistant）
        content: 内容（字符串或内容块列表）
    """
    role: str  # "user" or "assistant"
    content: Union[str, List[AnthropicContentBlock], List[Dict[str, Any]]]

    model_config = {"extra": "allow"}


class AnthropicTool(BaseModel):
    """
    Anthropic 格式的工具。

    Attributes:
        name: 工具名称
        description: 工具描述
        input_schema: 输入参数的 JSON Schema
    """
    name: str
    description: Optional[str] = None
    input_schema: Dict[str, Any]

    model_config = {"extra": "allow"}


class AnthropicMessagesRequest(BaseModel):
    """
    Anthropic Messages API 请求。

    Attributes:
        model: 模型 ID
        messages: 消息列表
        max_tokens: 最大 token 数（必填）
        system: 系统提示词
        tools: 工具列表
        tool_choice: 工具选择策略
        temperature: 生成温度
        top_p: Top-p 采样
        top_k: Top-k 采样
        stop_sequences: 停止序列
        stream: 是否使用流式响应
        metadata: 请求元数据
        thinking: Extended thinking 设置
    """
    model: str
    messages: Annotated[List[AnthropicMessage], Field(min_length=1)]
    max_tokens: int  # Required in Anthropic API
    system: Optional[Union[str, List[Dict[str, Any]]]] = None
    tools: Optional[List[AnthropicTool]] = None
    tool_choice: Optional[Dict[str, Any]] = None
    temperature: Optional[float] = None
    top_p: Optional[float] = None
    top_k: Optional[int] = None
    stop_sequences: Optional[List[str]] = None
    stream: bool = False
    metadata: Optional[Dict[str, Any]] = None
    # Extended Thinking support
    thinking: Optional[Dict[str, Any]] = None  # {"type": "enabled", "budget_tokens": 1024}

    model_config = {"extra": "allow"}


class AnthropicUsage(BaseModel):
    """
    Anthropic 格式的 token 使用信息。

    Attributes:
        input_tokens: 输入 token 数
        output_tokens: 输出 token 数
    """
    input_tokens: int = 0
    output_tokens: int = 0


class AnthropicResponseContentBlock(BaseModel):
    """
    Anthropic 响应中的内容块。

    Attributes:
        type: 内容类型（text、tool_use、thinking）
        text: 文本内容
        id: tool_use ID
        name: 工具名称
        input: 工具输入数据
        thinking: thinking 内容
    """
    type: str  # "text", "tool_use", "thinking"
    text: Optional[str] = None
    id: Optional[str] = None
    name: Optional[str] = None
    input: Optional[Dict[str, Any]] = None
    thinking: Optional[str] = None


class AnthropicMessagesResponse(BaseModel):
    """
    Anthropic Messages API 响应。

    Attributes:
        id: 响应唯一 ID
        type: 对象类型（始终为 "message"）
        role: 角色（始终为 "assistant"）
        content: 内容块列表
        model: 使用的模型
        stop_reason: 停止原因
        stop_sequence: 触发的停止序列
        usage: Token 使用信息
    """
    id: str
    type: str = "message"
    role: str = "assistant"
    content: List[AnthropicResponseContentBlock]
    model: str
    stop_reason: Optional[str] = None  # "end_turn", "max_tokens", "tool_use", "stop_sequence"
    stop_sequence: Optional[str] = None
    usage: AnthropicUsage